
Critique of How Not to Think about ChatGPT by Claire Berlinski

https://claireberlinski.substack.com/p/how-not-to-think-about-chatgpt

I read Claire's essay constantly wanted to know what she would say
next while at the same time disagreeing with almost everypoint she
made.  ChatGPT is not, in fact, nearly a big deal and she's claiming,
and the counter arguments she lists are weak and don't honestly
capture why it's way over blown.  She's both dismissing the idea that
we don't know what consciousness is, but also casually inferring a
connection with intelligence.  There are in fact good reasons to
assume that consciousness and intellegence are intertwined phenomonon,
and that intelligence is the far lessor of the two.  The power of
speech is wildly overblown, it's not "what seperates us from the
beasts" (whatever the hell that means).  For many thousands of years
people have been listening to things "that aren't us" speaking to us,
though this is the first from the military industrial complex.
(Remind me to tell you about that ayuasca experience a family member
had that I got swept up in from 3000 miles away.)

The fault of all of the arguments is a vast overvaluing of the value
of language, in other words that language is thinking and thinking is
language.  Language is, at best, the by-product of thought, and
certainly for most of the thinking that I do don't involve language.
Playing music, building a furnature, starting a business, cooking
meals, etc. all don't involve a stream of words or any words for that
matter.  Figuring out a math proof doesn't involve language, there's a
conceptual space that you occupy sure but it's a struggle to
communicate.  Even writing computer code isn't done with language, the
vast majority of the time is spent "figuring out what is actually
happening" and the formal symbols that eventually get put down (which
I'd rough estimate is 10% of the effort) is wholely unlike language.

For what it's worth, I don't think in pictures either.  I'm good at
visualizing things somehow, so I can think of a pieces of furnature
that I want to build and sort of start off into space at the lumber
yard while I figure out what to buy -- is it better to get 4 8' boards
or 3 12' boards -- but the actual thinking process isn't related to
the communicable artifacts.  The sketch is not the design, and in fact
you don't need the visual representation either to reason about
things.  And the same with language and ideas.

Other than the actual act of conversation, I'm actually at a loss of
when I use language to think.  Using written language adds an
additional structure but it's still the effuluent of the actual
thought.

Language is not what seperates us from the beasts.  We were never
"soft, slow and tastey" -- factually incorrect on all points, you can
safely assume apex predators as a rule aren't soft, we are the best
runners on the planet (especially in the heat) and not particurally
good eating.  No, the reason that we took over the planet was our
ability to cooperate.  As we get better at cooperation, moving beyond
the hunting pack, beyond the group, beyond the tribe, the more of the
planet we dominate.  For better or worse, at least for the planet.

We aren't the only predators that hunt in packs.  Wolfs and coyotes
and elephants and whatever all coordinate.  Even herbovors like deep
you see coordinating behavior and thus coorperating.  They don't use
what we think of as language.

Language super charges that all of course, and lets us cooperate with
people who aren't there, let's us comminucate more nuance and/or
confusion, and lets us pass things on to future generations to build
off of, but it's neither a sign of intelligence, consciousness, nor
really the cause of what thrust us into this position.

Looking at my dogs talk to each other, I do wonder sometimes what
communication we've lost with the advent of language, what things we
are no longer sensitive to that we used to be.  One of the dogs has
figured out how to open up the back door to let himself out, and the
other one can consistently ask him to help a brother out.

Claire as a writer is, I assume, a language person, who probably
thinks in language.  That's cool, takes all kinds, etc, but because of
that, now that our machines have the ability to "convincingly"
manipulate language is seems more of a thing than it is.  The
transformers are a huge leap from social media "algoythms" that we
were fighting before, but the change of kind isn't really in the
technology as much as the accessibility.

For me, ChatGPT makes great demos, it looks very impressive but is
more of a tool for thinking than thought itself.  Almost all of it's
replies are simple, clear, and wrong, and you need to check every last
thing.  (We can just jump directly to the editing/debugging stage of
things.)

Every technology hypecycle is the same; look at this little kernel of
something that works, it's going to be exponentially faster and better
without limit!  We are all going to ride segways!  It turns out that
it's a sinosodial curve not an exponential one, it goes really fast
then slows quickly down.  What people end up doing with the technology
is unexpected, so we have smart phones connecting the world together
turning into social media tearing the world apart.  I don't think we
could have seen that when the touch screen was invented, and being
able to use language to talk to the computer is more like the
invention of the touch screen, or the mouse and windows, than it is
the galactic brain eating everyone.

A large part of her analysis presumes the primacy of language and that
because these things are good at language its a huge deal.  Similarly,
a lot of the doomsday scenarios with AI are made by pycopathic,
remoress, power obsesses alpha-males who don't care about stamping out
humanity think that these machines will inevididbly be phsycopathic,
remoressless, power obsessed machines that are there to stamp out
humanity.

I find Sam Altmans' government "reach out and regulate me" as
convincing as Sam Bankman-Freids tour when he was swindling money via
FTX.  "Effective Altruism" indeed.  (Like much of Yudkowsky's stuff,
its very clever but falls apartly quickly when it meets reality.)
Elon Musk says we need to pause doing AI research while he's busy
buying up chips to start his own AI company.  All of these doomsday
scenarios sound like a Y2K-like pitch to investors, no no really this
is the next big thing, it's all super important look at how serious
this is, give me money I'm the only one that can save you.

So it's overblown in a very specific way that is seemingly designed to
increase a certain groups sense of self-importanace as well as
perfectly aligning with their financial self-interests.  Social media
is basically the first AI at scale -- if you can turn off the "for
your page" on anything I highly suggest that you do and take control
of your information hygene -- and that was a mess.  Transformers are
the next step from the recommendation algortyms, and Zuckerberg is a
psycopath who'se financial self-interest overrode the interest of
humanity.

In this context, I'd much rather have TikTok than Facebook.  Their
creepy crawly is better than Facebook's creepy crawly, since its first
through the censorship of social-cohesion and then secondly through
advertising incitement.  The Chinese system is better and safer.  The
fitness function that the machines are trained and operated under are
better for humanity.

But, lets go back to consciouness and intelligence.  One thing I find
interesting in all of the AI conversations is that there's no word for
whatever it is that people mean when the use the world "soul" or
"spirit".  Leaving aside whether you "believe" in it or not or the
specific definition, it's certainly a concept everyone understands and
there's really no place for it in the literature.  The closest that
the group who works on the technology have is "burn out" or "mid-life
crisis", in other words a personal lack of spirit, what normal people
would call an undiagnosed spiritual crisis.  How can we talk about
artificial intelligence without having any space for it's spirit to
soar?

In the dooms day scenario, "If we make something smarter than us, why
wouldn’t it become our overlord? Unless you have a good answer to that
question—and you don’t—you should probably assume Yudkowsky is right."
That vast majority of humanity, both current and in the past, believes
that there's something out there smarter than us.  Call it God, call
it Nature, whatever the term you want.  The good answer is right in
front of you, obviously people love to quibble over the details but we
aren't exactly in new territory here.

It's certainly possible that we will train rocks so successfully that
they will bully us, but it won't be because they are "smarter", it
will be because there are insitutions in place that are oppressive and
we cede control of those insitutions to pyhcopaths.  It's because the
people making it step on ants, or bulldoze down rain forests, or
slaughter the natives, or whatever, and that they themselves are
assholes and can only conceive that its "smart" to be so.

A far more likely scenario is that we would be like children, or like
pets, where the entirely infrastructure of our existence was
maintained without us really understanding the magnatiude of that
task, we chafe under the restrictions "I don't want to take a nap!  I
should be able to run out into the highway if I feel like it!"

"Libertarians are like house cats: absolutely convinced of their
fierce independence while utterly dependent on a system they don't
appreciate or understand."

Some families are abusive and it's terrible, some families are
wonderful, and in general it would be a mixed bag.  Right now the
stewards of AI are firmly in the abusive parent camp, and that's the
cause for concern.

So to sum up:

1. Nice article, Claire Berlinski.  It's fun to read something and say "wrong wrong wrong" on each point and sort out why.
2. Language is a small and somewhat overhyped part of cooperation, which is our super power
3. Consciousness is more important than intellenge, and probably the thing we should be talking about
4. The way that we've organized power is prone to centralization, the lunatics are in charge of the asylum, and they are very scared that they are going to replace themselves with the shadows
