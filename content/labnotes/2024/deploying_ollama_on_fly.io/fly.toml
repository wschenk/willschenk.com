app = 'llama-ollama'
primary_region = 'ord'

[http_service]
  internal_port = 8080
  auto_stop_machines = true
  auto_start_machines = true
  min_machines_running = 0
  processes = ['app']

[[vm]]
  size = 'a100-40gb'

[mounts]
  source = "models"
  destination = "/root/.ollama"
  initial_size = "100gb"
